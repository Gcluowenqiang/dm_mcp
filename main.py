#!/usr/bin/env python3
"""
è¾¾æ¢¦æ•°æ®åº“MCPæœåŠ¡
ä¸“ä¸ºCursorè®¾è®¡ï¼Œæä¾›è¡¨ç»“æ„æŸ¥è¯¢å’Œæ–‡æ¡£ç”ŸæˆåŠŸèƒ½
æ”¯æŒå¤šç§å®‰å…¨æ¨¡å¼

Copyright (c) 2025 qyue
Licensed under the MIT License.
See LICENSE file in the project root for full license information.
"""

import asyncio
import json
import sys
import os
from datetime import datetime
from typing import Any, Sequence
import logging

from mcp.server.models import InitializationOptions
from mcp.server import NotificationOptions, Server
from mcp.server.stdio import stdio_server
from mcp.server.fastmcp import FastMCP
from mcp.types import (
    Resource, 
    Tool, 
    TextContent, 
    ImageContent, 
    EmbeddedResource, 
    LoggingLevel
)
from pydantic import AnyUrl

from database import get_db_instance
from document_generator import doc_generator
from config import get_config_instance

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def normalize_data(data_list):
    """æ ‡å‡†åŒ–æ•°æ®ï¼Œå°†å¤§å†™å­—æ®µåè½¬æ¢ä¸ºå°å†™ï¼ˆä¿æŒåŸå­—æ®µåä½œä¸ºå¤‡ä»½ï¼‰"""
    normalized = []
    for item in data_list:
        normalized_item = {}
        for key, value in item.items():
            # ä¿ç•™åŸå­—æ®µå
            normalized_item[key] = value
            # æ·»åŠ å°å†™å­—æ®µå
            normalized_item[key.lower()] = value
        normalized.append(normalized_item)
    return normalized

def create_error_response(error_msg: str, error_type: str = "error") -> list[TextContent]:
    """åˆ›å»ºç»Ÿä¸€çš„é”™è¯¯å“åº”"""
    logger.error(f"{error_type}: {error_msg}")
    return [TextContent(
        type="text",
        text=f"âŒ {error_type.upper()}: {error_msg}"
    )]

def create_success_response(success_msg: str) -> list[TextContent]:
    """åˆ›å»ºç»Ÿä¸€çš„æˆåŠŸå“åº”"""
    logger.info(f"Success: {success_msg}")
    return [TextContent(
        type="text",
        text=f"âœ… {success_msg}"
    )]

# åˆ›å»ºMCPæœåŠ¡å™¨
server = Server("dm-mcp")

@server.list_tools()
async def handle_list_tools() -> list[Tool]:
    """
    åˆ—å‡ºå¯ç”¨çš„å·¥å…·
    """
    return [
        Tool(
            name="test_connection",
            description="æµ‹è¯•è¾¾æ¢¦æ•°æ®åº“è¿æ¥",
            inputSchema={
                "type": "object",
                "properties": {},
                "required": []
            }
        ),
        Tool(
            name="get_security_info",
            description="è·å–å½“å‰å®‰å…¨é…ç½®ä¿¡æ¯",
            inputSchema={
                "type": "object",
                "properties": {},
                "required": []
            }
        ),
        Tool(
            name="list_tables",
            description="è·å–æ•°æ®åº“ä¸­æ‰€æœ‰è¡¨çš„åˆ—è¡¨",
            inputSchema={
                "type": "object",
                "properties": {
                    "schema": {
                        "type": "string",
                        "description": "æ•°æ®åº“æ¨¡å¼åç§°",
                        "default": "SYSDBA"
                    }
                },
                "required": []
            }
        ),
        Tool(
            name="describe_table",
            description="è·å–æŒ‡å®šè¡¨çš„è¯¦ç»†ç»“æ„ä¿¡æ¯",
            inputSchema={
                "type": "object",
                "properties": {
                    "table_name": {
                        "type": "string",
                        "description": "è¡¨å"
                    },
                    "schema": {
                        "type": "string",
                        "description": "æ•°æ®åº“æ¨¡å¼åç§°",
                        "default": "SYSDBA"
                    }
                },
                "required": ["table_name"]
            }
        ),
        Tool(
            name="generate_table_doc",
            description="ç”Ÿæˆè¡¨ç»“æ„è®¾è®¡æ–‡æ¡£å¹¶ä¿å­˜ä¸ºæ–‡ä»¶ï¼ˆæ”¯æŒMarkdownã€JSONã€SQLæ ¼å¼ï¼‰",
            inputSchema={
                "type": "object",
                "properties": {
                    "table_name": {
                        "type": "string",
                        "description": "è¡¨å"
                    },
                    "schema": {
                        "type": "string",
                        "description": "æ•°æ®åº“æ¨¡å¼åç§°",
                        "default": "SYSDBA"
                    },
                    "format": {
                        "type": "string",
                        "description": "æ–‡æ¡£æ ¼å¼: markdown, json, sql",
                        "enum": ["markdown", "json", "sql"],
                        "default": "markdown"
                    }
                },
                "required": ["table_name"]
            }
        ),
        Tool(
            name="generate_database_overview",
            description="ç”Ÿæˆæ•°æ®åº“æ¦‚è§ˆæ–‡æ¡£å¹¶ä¿å­˜ä¸ºMarkdownæ–‡ä»¶",
            inputSchema={
                "type": "object",
                "properties": {
                    "schema": {
                        "type": "string",
                        "description": "æ•°æ®åº“æ¨¡å¼åç§°",
                        "default": "SYSDBA"
                    }
                },
                "required": []
            }
        ),
        Tool(
            name="execute_query",
            description="æ‰§è¡ŒSQLè¯­å¥ï¼ˆæ ¹æ®å®‰å…¨æ¨¡å¼é™åˆ¶æ“ä½œç±»å‹ï¼‰",
            inputSchema={
                "type": "object",
                "properties": {
                    "sql": {
                        "type": "string",
                        "description": "SQLè¯­å¥"
                    }
                },
                "required": ["sql"]
            }
        ),
        Tool(
            name="list_schemas",
            description="è·å–ç”¨æˆ·æœ‰æƒé™è®¿é—®çš„æ‰€æœ‰æ•°æ®åº“æ¨¡å¼",
            inputSchema={
                "type": "object",
                "properties": {},
                "required": []
            }
        ),
        Tool(
            name="generate_relationship_doc",
            description="ç”Ÿæˆæ•°æ®åº“è¡¨å…³ç³»å›¾æ–‡æ¡£ï¼ˆæ”¯æŒMermaidæ ¼å¼ï¼‰",
            inputSchema={
                "type": "object",
                "properties": {
                    "schema": {
                        "type": "string",
                        "description": "æ•°æ®åº“æ¨¡å¼åç§°",
                        "default": "SYSDBA"
                    }
                },
                "required": []
            }
        ),
        Tool(
            name="batch_generate_table_docs",
            description="æ‰¹é‡ç”Ÿæˆå¤šä¸ªè¡¨çš„æ–‡æ¡£",
            inputSchema={
                "type": "object",
                "properties": {
                    "table_names": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "è¡¨ååˆ—è¡¨"
                    },
                    "schema": {
                        "type": "string",
                        "description": "æ•°æ®åº“æ¨¡å¼åç§°",
                        "default": "SYSDBA"
                    },
                    "format": {
                        "type": "string",
                        "description": "æ–‡æ¡£æ ¼å¼: markdown, json, sql",
                        "enum": ["markdown", "json", "sql"],
                        "default": "markdown"
                    }
                },
                "required": ["table_names"]
            }
        ),
        Tool(
            name="export_to_excel",
            description="å¯¼å‡ºè¡¨ç»“æ„æˆ–æ•°æ®ä¸ºExcelæ ¼å¼",
            inputSchema={
                "type": "object",
                "properties": {
                    "table_name": {
                        "type": "string",
                        "description": "è¡¨å"
                    },
                    "schema": {
                        "type": "string",
                        "description": "æ•°æ®åº“æ¨¡å¼åç§°",
                        "default": "SYSDBA"
                    },
                    "export_type": {
                        "type": "string",
                        "description": "å¯¼å‡ºç±»å‹: structure, data, both",
                        "enum": ["structure", "data", "both"],
                        "default": "structure"
                    },
                    "data_limit": {
                        "type": "number",
                        "description": "æ•°æ®å¯¼å‡ºè¡Œæ•°é™åˆ¶",
                        "default": 1000
                    },
                    "fast_mode": {
                        "type": "boolean",
                        "description": "å¿«é€Ÿæ¨¡å¼ï¼ˆç¦ç”¨æ ·å¼ï¼Œæé«˜å¯¼å‡ºé€Ÿåº¦ï¼‰",
                        "default": True
                    }
                },
                "required": ["table_name"]
            }
        ),
        Tool(
            name="get_cache_info",
            description="è·å–æŸ¥è¯¢ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯",
            inputSchema={
                "type": "object",
                "properties": {},
                "required": []
            }
        ),
        Tool(
            name="clear_cache",
            description="æ¸…ç©ºæŸ¥è¯¢ç¼“å­˜",
            inputSchema={
                "type": "object",
                "properties": {},
                "required": []
            }
        )
    ]

@server.call_tool()
async def handle_call_tool(name: str, arguments: dict[str, Any] | None) -> list[TextContent | ImageContent | EmbeddedResource]:
    """
    å¤„ç†å·¥å…·è°ƒç”¨
    """
    try:
        # è·å–æ•°æ®åº“å®ä¾‹
        db = get_db_instance()
        
        if name == "test_connection":
            result = db.test_connection()
            return [TextContent(
                type="text",
                text=f"è¾¾æ¢¦æ•°æ®åº“è¿æ¥æµ‹è¯•: {'æˆåŠŸ' if result else 'å¤±è´¥'}"
            )]
        
        elif name == "get_security_info":
            security_info = db.get_security_info()
            info_text = "å½“å‰å®‰å…¨é…ç½®ä¿¡æ¯:\n\n"
            info_text += f"å®‰å…¨æ¨¡å¼: {security_info['security_mode']}\n"
            info_text += f"åªè¯»æ¨¡å¼: {'æ˜¯' if security_info['readonly_mode'] else 'å¦'}\n"
            info_text += f"å…è®¸å†™å…¥æ“ä½œ: {'æ˜¯' if security_info['write_allowed'] else 'å¦'}\n"
            info_text += f"å…è®¸å±é™©æ“ä½œ: {'æ˜¯' if security_info['dangerous_operations_allowed'] else 'å¦'}\n"
            info_text += f"å…è®¸è®¿é—®çš„æ¨¡å¼: {', '.join(security_info['allowed_schemas'])}\n"
            info_text += f"æœ€å¤§è¿”å›è¡Œæ•°: {security_info['max_result_rows']}\n"
            info_text += f"æŸ¥è¯¢æ—¥å¿—: {'å¯ç”¨' if security_info['query_log_enabled'] else 'ç¦ç”¨'}\n"
            
            return [TextContent(type="text", text=info_text)]
        
        elif name == "list_tables":
            schema = arguments.get("schema", "SYSDBA") if arguments else "SYSDBA"
            tables = db.get_all_tables(schema)
            
            if not tables:
                return [TextContent(
                    type="text",
                    text=f"åœ¨æ¨¡å¼ '{schema}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è¡¨"
                )]
            
            # è¾¾æ¢¦æ•°æ®åº“å­—æ®µåå¯èƒ½æ˜¯å¤§å†™ï¼Œå°è¯•ä¸¤ç§æ ¼å¼
            table_list = "\n".join([f"- {table.get('tablename') or table.get('TABLENAME', 'Unknown')}" for table in tables])
            return [TextContent(
                type="text",
                text=f"æ¨¡å¼ '{schema}' ä¸­çš„è¡¨åˆ—è¡¨:\n{table_list}\n\næ€»è®¡: {len(tables)} ä¸ªè¡¨"
            )]
        
        elif name == "describe_table":
            if not arguments or "table_name" not in arguments:
                return create_error_response("ç¼ºå°‘å¿…éœ€çš„å‚æ•° 'table_name'", "å‚æ•°é”™è¯¯")
            
            table_name = arguments["table_name"]
            schema = arguments.get("schema", "SYSDBA")
            
            # è·å–è¡¨ç»“æ„ä¿¡æ¯
            structure = db.get_table_structure(table_name, schema)
            indexes = db.get_table_indexes(table_name, schema)
            constraints = db.get_table_constraints(table_name, schema)
            table_comment = db.get_table_comment(table_name, schema)
            
            if not structure:
                return [TextContent(
                    type="text",
                    text=f"è¡¨ '{table_name}' åœ¨æ¨¡å¼ '{schema}' ä¸­ä¸å­˜åœ¨"
                )]
            
            # æ ¼å¼åŒ–è¾“å‡º
            result = f"è¡¨ '{table_name}' ç»“æ„ä¿¡æ¯:\n\n"
            if table_comment:
                result += f"è¡¨æ³¨é‡Š: {table_comment}\n\n"
            result += "å­—æ®µåˆ—è¡¨:\n"
            for col in structure:
                # è¾¾æ¢¦æ•°æ®åº“å­—æ®µåå¯èƒ½æ˜¯å¤§å†™ï¼Œå°è¯•ä¸¤ç§æ ¼å¼
                column_name = col.get('column_name') or col.get('COLUMN_NAME', 'Unknown')
                data_type = col.get('data_type') or col.get('DATA_TYPE', 'Unknown')
                is_nullable = col.get('is_nullable') or col.get('IS_NULLABLE', 'YES')
                is_primary_key = col.get('is_primary_key') or col.get('IS_PRIMARY_KEY', 'NO')
                column_comment = col.get('column_comment') or col.get('COLUMN_COMMENT', '')
                
                result += f"- {column_name} ({data_type}) "
                if is_nullable == 'NO':
                    result += "NOT NULL "
                if is_primary_key == 'YES':
                    result += "[ä¸»é”®] "
                if column_comment:
                    result += f"-- {column_comment}"
                result += "\n"
            
            if indexes:
                result += f"\nç´¢å¼• ({len(indexes)} ä¸ª):\n"
                for idx in indexes:
                    # è¾¾æ¢¦æ•°æ®åº“å­—æ®µåå¯èƒ½æ˜¯å¤§å†™ï¼Œå°è¯•ä¸¤ç§æ ¼å¼
                    indexname = idx.get('indexname') or idx.get('INDEXNAME', 'Unknown')
                    is_unique = idx.get('is_unique') or idx.get('IS_UNIQUE', 'NO')
                    result += f"- {indexname} {'[å”¯ä¸€]' if is_unique == 'YES' else ''}\n"
            
            if constraints:
                result += f"\nçº¦æŸ ({len(constraints)} ä¸ª):\n"
                for constraint in constraints:
                    # è¾¾æ¢¦æ•°æ®åº“å­—æ®µåå¯èƒ½æ˜¯å¤§å†™ï¼Œå°è¯•ä¸¤ç§æ ¼å¼
                    constraint_name = constraint.get('constraint_name') or constraint.get('CONSTRAINT_NAME', 'Unknown')
                    constraint_type = constraint.get('constraint_type') or constraint.get('CONSTRAINT_TYPE', 'Unknown')
                    result += f"- {constraint_name} ({constraint_type})\n"
            
            return [TextContent(type="text", text=result)]
        
        elif name == "generate_table_doc":
            if not arguments or "table_name" not in arguments:
                return create_error_response("ç¼ºå°‘å¿…éœ€çš„å‚æ•° 'table_name'", "å‚æ•°é”™è¯¯")
            
            try:
                table_name = arguments["table_name"]
                schema = arguments.get("schema", "SYSDBA")
                format_type = arguments.get("format", "markdown")
                
                # è·å–è¡¨ä¿¡æ¯
                structure = db.get_table_structure(table_name, schema)
                indexes = db.get_table_indexes(table_name, schema)
                constraints = db.get_table_constraints(table_name, schema)
                table_comment = db.get_table_comment(table_name, schema)
                
                if not structure:
                    return [TextContent(
                        type="text",
                        text=f"è¡¨ '{table_name}' åœ¨æ¨¡å¼ '{schema}' ä¸­ä¸å­˜åœ¨"
                    )]
                
                # é¢„å¤„ç†æ•°æ®ï¼Œç¡®ä¿å­—æ®µåå…¼å®¹æ€§
                structure = normalize_data(structure)
                indexes = normalize_data(indexes)
                constraints = normalize_data(constraints)
                
                # ç”Ÿæˆæ–‡æ¡£
                if format_type == "markdown":
                    doc = doc_generator.generate_table_structure_doc(table_name, structure, indexes, constraints, schema, table_comment)
                    file_ext = ".md"
                elif format_type == "json":
                    doc = doc_generator.generate_json_structure(table_name, structure, indexes, constraints, schema, table_comment)
                    file_ext = ".json"
                elif format_type == "sql":
                    doc = doc_generator.generate_sql_create_statement(table_name, structure, table_comment)
                    file_ext = ".sql"
                else:
                    return [TextContent(
                        type="text",
                        text=f"ä¸æ”¯æŒçš„æ–‡æ¡£æ ¼å¼: {format_type}"
                    )]
                
                # ç¡®ä¿åœ¨MCPæœåŠ¡ç›®å½•ä¸‹åˆ›å»ºdocsç›®å½•
                service_dir = os.path.dirname(os.path.abspath(__file__))  # è·å–MCPæœåŠ¡æ‰€åœ¨ç›®å½•
                docs_dir = os.path.join(service_dir, "docs")
                os.makedirs(docs_dir, exist_ok=True)
                
                # ç”Ÿæˆæ–‡ä»¶å
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"{schema}_{table_name}_{timestamp}{file_ext}"
                file_path = os.path.join(docs_dir, filename)
                
                # ä¿å­˜æ–‡æ¡£åˆ°æ–‡ä»¶
                try:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(doc)
                    
                    # è¿”å›æˆåŠŸä¿¡æ¯å’Œæ–‡æ¡£é¢„è§ˆ
                    # æ˜¾ç¤ºMCPæœåŠ¡ç›®å½•çš„ç›¸å¯¹è·¯å¾„
                    relative_path = os.path.relpath(file_path, service_dir)
                    result_text = f"âœ… æ–‡æ¡£ç”ŸæˆæˆåŠŸ!\n\n"
                    result_text += f"ğŸ“ ä¿å­˜è·¯å¾„: {relative_path}\n"
                    result_text += f"ğŸ“‚ MCPæœåŠ¡ç›®å½•: {service_dir}\n"
                    result_text += f"ğŸ“Š è¡¨å: {schema}.{table_name}\n"
                    result_text += f"ğŸ“ æ ¼å¼: {format_type}\n"
                    result_text += f"â° ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
                    result_text += "ğŸ“„ æ–‡æ¡£å†…å®¹é¢„è§ˆ:\n"
                    result_text += "=" * 50 + "\n"
                    
                    # é™åˆ¶é¢„è§ˆé•¿åº¦
                    preview = doc[:1000] + "..." if len(doc) > 1000 else doc
                    result_text += preview
                    
                    return [TextContent(type="text", text=result_text)]
                    
                except Exception as file_error:
                    # å¦‚æœæ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œä»ç„¶è¿”å›æ–‡æ¡£å†…å®¹
                    error_msg = f"âš ï¸ æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(file_error)}\n\n"
                    error_msg += "ğŸ“„ ç”Ÿæˆçš„æ–‡æ¡£å†…å®¹:\n"
                    error_msg += "=" * 50 + "\n"
                    error_msg += doc
                    return [TextContent(type="text", text=error_msg)]
            
            except Exception as e:
                return [TextContent(
                    type="text",
                    text=f"ç”Ÿæˆæ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
                )]
        
        elif name == "generate_database_overview":
            try:
                schema = arguments.get("schema", "SYSDBA") if arguments else "SYSDBA"
                tables = db.get_all_tables(schema)
                
                # é¢„å¤„ç†æ•°æ®ï¼Œç¡®ä¿å­—æ®µåå…¼å®¹æ€§
                tables = normalize_data(tables)
                
                # ç”Ÿæˆæ•°æ®åº“æ¦‚è§ˆæ–‡æ¡£
                doc = doc_generator.generate_database_overview_doc(tables, schema)
                
                # ç¡®ä¿åœ¨MCPæœåŠ¡ç›®å½•ä¸‹åˆ›å»ºdocsç›®å½•
                service_dir = os.path.dirname(os.path.abspath(__file__))  # è·å–MCPæœåŠ¡æ‰€åœ¨ç›®å½•
                docs_dir = os.path.join(service_dir, "docs")
                os.makedirs(docs_dir, exist_ok=True)
                
                # ç”Ÿæˆæ–‡ä»¶å
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"{schema}_æ•°æ®åº“æ¦‚è§ˆ_{timestamp}.md"
                file_path = os.path.join(docs_dir, filename)
                
                # ä¿å­˜æ–‡æ¡£åˆ°æ–‡ä»¶
                try:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(doc)
                    
                    # è¿”å›æˆåŠŸä¿¡æ¯å’Œæ–‡æ¡£é¢„è§ˆ
                    # æ˜¾ç¤ºMCPæœåŠ¡ç›®å½•çš„ç›¸å¯¹è·¯å¾„
                    relative_path = os.path.relpath(file_path, service_dir)
                    result_text = f"âœ… æ•°æ®åº“æ¦‚è§ˆæ–‡æ¡£ç”ŸæˆæˆåŠŸ!\n\n"
                    result_text += f"ğŸ“ ä¿å­˜è·¯å¾„: {relative_path}\n"
                    result_text += f"ğŸ“‚ MCPæœåŠ¡ç›®å½•: {service_dir}\n"
                    result_text += f"ğŸ—‚ï¸ æ¨¡å¼: {schema}\n"
                    result_text += f"ğŸ“‹ è¡¨æ•°é‡: {len(tables)} ä¸ª\n"
                    result_text += f"â° ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
                    result_text += "ğŸ“„ æ–‡æ¡£å†…å®¹é¢„è§ˆ:\n"
                    result_text += "=" * 50 + "\n"
                    
                    # é™åˆ¶é¢„è§ˆé•¿åº¦
                    preview = doc[:1000] + "..." if len(doc) > 1000 else doc
                    result_text += preview
                    
                    return [TextContent(type="text", text=result_text)]
                    
                except Exception as file_error:
                    # å¦‚æœæ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œä»ç„¶è¿”å›æ–‡æ¡£å†…å®¹
                    error_msg = f"âš ï¸ æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(file_error)}\n\n"
                    error_msg += "ğŸ“„ ç”Ÿæˆçš„æ–‡æ¡£å†…å®¹:\n"
                    error_msg += "=" * 50 + "\n"
                    error_msg += doc
                    return [TextContent(type="text", text=error_msg)]
                    
            except Exception as e:
                return [TextContent(
                    type="text",
                    text=f"ç”Ÿæˆæ•°æ®åº“æ¦‚è§ˆæ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
                )]
        
        elif name == "execute_query":
            if not arguments or "sql" not in arguments:
                return create_error_response("ç¼ºå°‘å¿…éœ€çš„å‚æ•° 'sql'", "å‚æ•°é”™è¯¯")
            
            sql = arguments["sql"]
            
            try:
                results = db.execute_query(sql)
                
                if not results:
                    return [TextContent(
                        type="text",
                        text="è¯­å¥æ‰§è¡ŒæˆåŠŸï¼Œä½†æ²¡æœ‰è¿”å›ç»“æœ"
                    )]
                
                # æ ¼å¼åŒ–ç»“æœ
                if sql.upper().strip().startswith(('SELECT', 'WITH', 'SHOW', 'DESCRIBE', 'EXPLAIN')):
                    result_text = f"æŸ¥è¯¢ç»“æœ ({len(results)} æ¡è®°å½•):\n\n"
                    
                    if len(results) <= 100:  # é™åˆ¶æ˜¾ç¤ºæ¡æ•°
                        result_text += json.dumps(results, ensure_ascii=False, indent=2)
                    else:
                        result_text += f"ç»“æœé›†è¿‡å¤§ï¼Œä»…æ˜¾ç¤ºå‰100æ¡:\n"
                        result_text += json.dumps(results[:100], ensure_ascii=False, indent=2)
                        result_text += f"\n\n... (è¿˜æœ‰ {len(results) - 100} æ¡è®°å½•)"
                else:
                    # éæŸ¥è¯¢æ“ä½œçš„ç»“æœ
                    result_text = f"æ“ä½œæ‰§è¡ŒæˆåŠŸ:\n\n"
                    result_text += json.dumps(results, ensure_ascii=False, indent=2)
                
                return [TextContent(type="text", text=result_text)]
                
            except Exception as e:
                return [TextContent(
                    type="text",
                    text=f"SQLæ‰§è¡Œå¤±è´¥: {str(e)}"
                )]
        
        elif name == "list_schemas":
            try:
                schemas = db.get_available_schemas()
                
                if not schemas:
                    return [TextContent(
                        type="text",
                        text="æ²¡æœ‰æ‰¾åˆ°å¯è®¿é—®çš„æ•°æ®åº“æ¨¡å¼"
                    )]
                
                # è¾¾æ¢¦æ•°æ®åº“å­—æ®µåå¯èƒ½æ˜¯å¤§å†™ï¼Œå°è¯•ä¸¤ç§æ ¼å¼
                schema_list = "\n".join([f"- {schema.get('schemaname') or schema.get('SCHEMANAME', 'Unknown')}" for schema in schemas])
                
                config_info = f"å½“å‰schemaè®¿é—®ç­–ç•¥: {db._get_allowed_schemas_display()}\n\n"
                result_text = config_info + f"å¯è®¿é—®çš„æ•°æ®åº“æ¨¡å¼:\n{schema_list}\n\næ€»è®¡: {len(schemas)} ä¸ªæ¨¡å¼"
                
                return [TextContent(type="text", text=result_text)]
                
            except Exception as e:
                return [TextContent(
                    type="text",
                    text=f"è·å–schemaåˆ—è¡¨å¤±è´¥: {str(e)}"
                )]
        
        elif name == "generate_relationship_doc":
            try:
                schema = arguments.get("schema", "SYSDBA") if arguments else "SYSDBA"
                
                # è·å–è¡¨åˆ—è¡¨å’Œå…³ç³»ä¿¡æ¯
                tables = db.get_all_tables(schema)
                relationships = db.get_table_relationships(schema)
                
                # é¢„å¤„ç†æ•°æ®
                tables = normalize_data(tables)
                relationships = normalize_data(relationships)
                
                # ç”Ÿæˆå…³ç³»æ–‡æ¡£
                doc = doc_generator.generate_relationship_doc(tables, relationships, schema)
                
                # ä¿å­˜æ–‡æ¡£
                service_dir = os.path.dirname(os.path.abspath(__file__))
                docs_dir = os.path.join(service_dir, "docs")
                os.makedirs(docs_dir, exist_ok=True)
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"{schema}_è¡¨å…³ç³»å›¾_{timestamp}.md"
                file_path = os.path.join(docs_dir, filename)
                
                try:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(doc)
                    
                    relative_path = os.path.relpath(file_path, service_dir)
                    result_text = f"âœ… è¡¨å…³ç³»å›¾æ–‡æ¡£ç”ŸæˆæˆåŠŸ!\n\n"
                    result_text += f"ğŸ“ ä¿å­˜è·¯å¾„: {relative_path}\n"
                    result_text += f"ğŸ“‚ MCPæœåŠ¡ç›®å½•: {service_dir}\n"
                    result_text += f"ğŸ—‚ï¸ æ¨¡å¼: {schema}\n"
                    result_text += f"ğŸ“‹ è¡¨æ•°é‡: {len(tables)} ä¸ª\n"
                    result_text += f"ğŸ”— å…³ç³»æ•°é‡: {len(relationships)} ä¸ª\n"
                    result_text += f"â° ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
                    result_text += "ğŸ“„ æ–‡æ¡£å†…å®¹é¢„è§ˆ:\n"
                    result_text += "=" * 50 + "\n"
                    
                    preview = doc[:1000] + "..." if len(doc) > 1000 else doc
                    result_text += preview
                    
                    return [TextContent(type="text", text=result_text)]
                    
                except Exception as file_error:
                    error_msg = f"âš ï¸ æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(file_error)}\n\n"
                    error_msg += "ğŸ“„ ç”Ÿæˆçš„æ–‡æ¡£å†…å®¹:\n"
                    error_msg += "=" * 50 + "\n"
                    error_msg += doc
                    return [TextContent(type="text", text=error_msg)]
                    
            except Exception as e:
                return [TextContent(
                    type="text",
                    text=f"ç”Ÿæˆè¡¨å…³ç³»å›¾æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
                )]
        
        elif name == "batch_generate_table_docs":
            try:
                if not arguments or "table_names" not in arguments:
                    return create_error_response("ç¼ºå°‘å¿…éœ€çš„å‚æ•° 'table_names'", "å‚æ•°é”™è¯¯")
                
                table_names = arguments["table_names"]
                schema = arguments.get("schema", "SYSDBA")
                format_type = arguments.get("format", "markdown")
                
                if not isinstance(table_names, list) or not table_names:
                    return create_error_response("table_names å¿…é¡»æ˜¯éç©ºåˆ—è¡¨", "å‚æ•°é”™è¯¯")
                
                # æ‰¹é‡ç”Ÿæˆæ–‡æ¡£
                results = []
                service_dir = os.path.dirname(os.path.abspath(__file__))
                docs_dir = os.path.join(service_dir, "docs")
                os.makedirs(docs_dir, exist_ok=True)
                
                for table_name in table_names:
                    try:
                        # è·å–è¡¨ä¿¡æ¯
                        structure = db.get_table_structure(table_name, schema)
                        indexes = db.get_table_indexes(table_name, schema)
                        constraints = db.get_table_constraints(table_name, schema)
                        table_comment = db.get_table_comment(table_name, schema)
                        
                        if not structure:
                            results.append(f"âŒ è¡¨ '{table_name}' ä¸å­˜åœ¨")
                            continue
                        
                        # é¢„å¤„ç†æ•°æ®
                        structure = normalize_data(structure)
                        indexes = normalize_data(indexes)
                        constraints = normalize_data(constraints)
                        
                        # ç”Ÿæˆæ–‡æ¡£
                        if format_type == "markdown":
                            doc = doc_generator.generate_table_structure_doc(table_name, structure, indexes, constraints, schema, table_comment)
                            file_ext = ".md"
                        elif format_type == "json":
                            doc = doc_generator.generate_json_structure(table_name, structure, indexes, constraints, schema, table_comment)
                            file_ext = ".json"
                        elif format_type == "sql":
                            doc = doc_generator.generate_sql_create_statement(table_name, structure, table_comment)
                            file_ext = ".sql"
                        else:
                            results.append(f"âŒ è¡¨ '{table_name}': ä¸æ”¯æŒçš„æ ¼å¼ {format_type}")
                            continue
                        
                        # ä¿å­˜æ–‡æ¡£
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        filename = f"{schema}_{table_name}_{timestamp}{file_ext}"
                        file_path = os.path.join(docs_dir, filename)
                        
                        with open(file_path, 'w', encoding='utf-8') as f:
                            f.write(doc)
                        
                        results.append(f"âœ… è¡¨ '{table_name}': æ–‡æ¡£å·²ç”Ÿæˆ")
                        
                    except Exception as table_error:
                        results.append(f"âŒ è¡¨ '{table_name}': {str(table_error)}")
                
                # è¿”å›æ‰¹é‡å¤„ç†ç»“æœ
                result_text = f"âœ… æ‰¹é‡æ–‡æ¡£ç”Ÿæˆå®Œæˆ!\n\n"
                result_text += f"ğŸ“‚ ä¿å­˜ç›®å½•: docs/\n"
                result_text += f"ğŸ—‚ï¸ æ¨¡å¼: {schema}\n"
                result_text += f"ğŸ“ æ ¼å¼: {format_type}\n"
                result_text += f"ğŸ“‹ å¤„ç†è¡¨æ•°: {len(table_names)} ä¸ª\n"
                result_text += f"â° ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
                result_text += "ğŸ“Š å¤„ç†ç»“æœ:\n"
                result_text += "=" * 50 + "\n"
                result_text += "\n".join(results)
                
                return [TextContent(type="text", text=result_text)]
                
            except Exception as e:
                return [TextContent(
                    type="text",
                    text=f"æ‰¹é‡ç”Ÿæˆæ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
                )]
        
        elif name == "export_to_excel":
            try:
                if not arguments or "table_name" not in arguments:
                    return create_error_response("ç¼ºå°‘å¿…éœ€çš„å‚æ•° 'table_name'", "å‚æ•°é”™è¯¯")
                
                table_name = arguments["table_name"]
                schema = arguments.get("schema", "SYSDBA")
                export_type = arguments.get("export_type", "structure")
                data_limit = arguments.get("data_limit", 1000)
                fast_mode = arguments.get("fast_mode", True)
                
                # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†openpyxl
                try:
                    import openpyxl
                    from openpyxl.styles import Font, PatternFill, Alignment
                except ImportError:
                    return [TextContent(
                        type="text",
                        text="âŒ å¯¼å‡ºExcelåŠŸèƒ½éœ€è¦å®‰è£…openpyxlåº“\nè¯·è¿è¡Œ: pip install openpyxl"
                    )]
                
                # åˆ›å»ºExcelå·¥ä½œç°¿ï¼ˆä¼˜åŒ–ï¼šç¦ç”¨è‡ªåŠ¨è®¡ç®—ï¼‰
                wb = openpyxl.Workbook()
                wb.calculation.calcMode = 'manual'  # ç¦ç”¨è‡ªåŠ¨è®¡ç®—
                
                if export_type in ["structure", "both"]:
                    # å¯¼å‡ºè¡¨ç»“æ„
                    structure = db.get_table_structure(table_name, schema)
                    indexes = db.get_table_indexes(table_name, schema)
                    constraints = db.get_table_constraints(table_name, schema)
                    table_comment = db.get_table_comment(table_name, schema)
                    
                    if not structure:
                        return [TextContent(
                            type="text",
                            text=f"âŒ è¡¨ '{table_name}' åœ¨æ¨¡å¼ '{schema}' ä¸­ä¸å­˜åœ¨ï¼Œæ— æ³•å¯¼å‡º"
                        )]
                    
                    # åˆ›å»ºè¡¨ç»“æ„å·¥ä½œè¡¨
                    ws_structure = wb.active
                    ws_structure.title = "è¡¨ç»“æ„"
                    
                    # è®¾ç½®æ ‡é¢˜
                    ws_structure['A1'] = f"è¡¨ç»“æ„: {table_name}"
                    if not fast_mode:
                        ws_structure['A1'].font = Font(bold=True, size=14)
                    ws_structure['A2'] = f"æ¨¡å¼: {schema}"
                    ws_structure['A3'] = f"è¡¨æ³¨é‡Š: {table_comment or 'æ— '}"
                    ws_structure['A4'] = f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                    
                    # å­—æ®µä¿¡æ¯ï¼ˆä¼˜åŒ–ï¼šæ‰¹é‡å†™å…¥ï¼Œå‡å°‘æ ·å¼è®¾ç½®ï¼‰
                    headers = ['åºå·', 'å­—æ®µå', 'æ•°æ®ç±»å‹', 'é•¿åº¦', 'ç²¾åº¦', 'æ ‡åº¦', 'å¯ç©º', 'é»˜è®¤å€¼', 'ä¸»é”®', 'æ³¨é‡Š']
                    
                    # æ‰¹é‡å†™å…¥æ ‡é¢˜è¡Œ
                    for col, header in enumerate(headers, 1):
                        ws_structure.cell(row=6, column=col, value=header)
                    
                    # æ‰¹é‡å†™å…¥æ•°æ®è¡Œï¼ˆä¸è®¾ç½®æ ·å¼ä»¥æé«˜é€Ÿåº¦ï¼‰
                    for row_idx, col_data in enumerate(structure, 7):
                        ws_structure.cell(row=row_idx, column=1, value=col_data.get('ordinal_position', ''))
                        ws_structure.cell(row=row_idx, column=2, value=col_data.get('column_name', ''))
                        ws_structure.cell(row=row_idx, column=3, value=col_data.get('data_type', ''))
                        ws_structure.cell(row=row_idx, column=4, value=col_data.get('character_maximum_length', ''))
                        ws_structure.cell(row=row_idx, column=5, value=col_data.get('numeric_precision', ''))
                        ws_structure.cell(row=row_idx, column=6, value=col_data.get('numeric_scale', ''))
                        ws_structure.cell(row=row_idx, column=7, value=col_data.get('is_nullable', ''))
                        ws_structure.cell(row=row_idx, column=8, value=col_data.get('column_default', ''))
                        ws_structure.cell(row=row_idx, column=9, value=col_data.get('is_primary_key', ''))
                        ws_structure.cell(row=row_idx, column=10, value=col_data.get('column_comment', ''))
                
                if export_type in ["data", "both"]:
                    # å¯¼å‡ºè¡¨æ•°æ®
                    if export_type == "both":
                        ws_data = wb.create_sheet("è¡¨æ•°æ®")
                    else:
                        ws_data = wb.active
                        ws_data.title = "è¡¨æ•°æ®"
                    
                    # æŸ¥è¯¢è¡¨æ•°æ®
                    sql = f"SELECT * FROM {schema}.{table_name} LIMIT {data_limit}"
                    data_results = db.execute_query(sql, use_cache=False)
                    
                    if data_results:
                        # è®¾ç½®æ ‡é¢˜
                        ws_data['A1'] = f"è¡¨æ•°æ®: {table_name}"
                        if not fast_mode:
                            ws_data['A1'].font = Font(bold=True, size=14)
                        ws_data['A2'] = f"æ¨¡å¼: {schema}"
                        ws_data['A3'] = f"æ•°æ®è¡Œæ•°: {len(data_results)} (é™åˆ¶: {data_limit})"
                        ws_data['A4'] = f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                        
                        # å†™å…¥æ•°æ®ï¼ˆä¼˜åŒ–ï¼šæ‰¹é‡å†™å…¥ï¼Œå‡å°‘æ ·å¼è®¾ç½®ï¼‰
                        if data_results:
                            headers = list(data_results[0].keys())
                            # æ‰¹é‡å†™å…¥æ ‡é¢˜è¡Œ
                            for col, header in enumerate(headers, 1):
                                ws_data.cell(row=6, column=col, value=header)
                            
                            # æ‰¹é‡å†™å…¥æ•°æ®è¡Œï¼ˆä¸è®¾ç½®æ ·å¼ä»¥æé«˜é€Ÿåº¦ï¼‰
                            for row_idx, data_row in enumerate(data_results, 7):
                                for col_idx, (key, value) in enumerate(data_row.items(), 1):
                                    ws_data.cell(row=row_idx, column=col_idx, value=str(value) if value is not None else '')
                
                # ä¿å­˜Excelæ–‡ä»¶
                service_dir = os.path.dirname(os.path.abspath(__file__))
                docs_dir = os.path.join(service_dir, "docs")
                os.makedirs(docs_dir, exist_ok=True)
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"{schema}_{table_name}_å¯¼å‡º_{timestamp}.xlsx"
                file_path = os.path.join(docs_dir, filename)
                
                wb.save(file_path)
                
                relative_path = os.path.relpath(file_path, service_dir)
                result_text = f"âœ… Excelå¯¼å‡ºæˆåŠŸ!\n\n"
                result_text += f"ğŸ“ ä¿å­˜è·¯å¾„: {relative_path}\n"
                result_text += f"ğŸ“‚ MCPæœåŠ¡ç›®å½•: {service_dir}\n"
                result_text += f"ğŸ“Š è¡¨å: {schema}.{table_name}\n"
                result_text += f"ğŸ“ å¯¼å‡ºç±»å‹: {export_type}\n"
                if export_type in ["data", "both"]:
                    result_text += f"ğŸ“‹ æ•°æ®è¡Œæ•°: {len(data_results) if 'data_results' in locals() else 0}\n"
                result_text += f"â° ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                
                return [TextContent(type="text", text=result_text)]
                
            except Exception as e:
                return [TextContent(
                    type="text",
                    text=f"å¯¼å‡ºExcelæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
                )]
        
        elif name == "get_cache_info":
            try:
                cache_info = db.get_cache_info()
                
                result_text = "ğŸ“Š æŸ¥è¯¢ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯:\n\n"
                result_text += f"ç¼“å­˜å¤§å°: {cache_info['cache_size']} / {cache_info['max_size']} æ¡\n"
                result_text += f"ç¼“å­˜TTL: {cache_info['ttl']} ç§’\n"
                result_text += f"ç¼“å­˜æ¡ç›®æ•°: {len(cache_info['entries'])} ä¸ª\n\n"
                
                if cache_info['entries']:
                    result_text += "ğŸ“‹ ç¼“å­˜æ¡ç›®:\n"
                    for i, entry in enumerate(cache_info['entries'][:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
                        result_text += f"{i}. {entry[:20]}...\n"
                    if len(cache_info['entries']) > 10:
                        result_text += f"... è¿˜æœ‰ {len(cache_info['entries']) - 10} ä¸ªæ¡ç›®\n"
                
                return [TextContent(type="text", text=result_text)]
                
            except Exception as e:
                return [TextContent(
                    type="text",
                    text=f"è·å–ç¼“å­˜ä¿¡æ¯å¤±è´¥: {str(e)}"
                )]
        
        elif name == "clear_cache":
            try:
                db.clear_cache()
                return [TextContent(
                    type="text",
                    text="âœ… æŸ¥è¯¢ç¼“å­˜å·²æ¸…ç©º"
                )]
                
            except Exception as e:
                return [TextContent(
                    type="text",
                    text=f"æ¸…ç©ºç¼“å­˜å¤±è´¥: {str(e)}"
                )]
        
        else:
            return create_error_response(f"æœªçŸ¥çš„å·¥å…·: {name}", "å·¥å…·é”™è¯¯")
    
    except Exception as e:
        return create_error_response(f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}", "ç³»ç»Ÿé”™è¯¯")

async def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–é…ç½®å’Œæ•°æ®åº“è¿æ¥æµ‹è¯•
    logger.info("å¯åŠ¨è¾¾æ¢¦æ•°æ®åº“MCPæœåŠ¡...")
    
    try:
        # è·å–é…ç½®ä¿¡æ¯
        config = get_config_instance()
        logger.info(f"é…ç½®åŠ è½½æˆåŠŸï¼Œå®‰å…¨æ¨¡å¼: {config.security_mode.value}")
        
        # è·å–æ•°æ®åº“å®ä¾‹å¹¶æµ‹è¯•è¿æ¥
        db = get_db_instance()
        if db.test_connection():
            logger.info("è¾¾æ¢¦æ•°æ®åº“è¿æ¥æµ‹è¯•æˆåŠŸ")
        else:
            logger.warning("è¾¾æ¢¦æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥ï¼ŒæœåŠ¡ä»å°†å¯åŠ¨")
            
    except Exception as e:
        logger.error(f"æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        logger.error("è¯·æ£€æŸ¥Cursor MCPé…ç½®ä¸­çš„ç¯å¢ƒå˜é‡è®¾ç½®")
        sys.exit(1)
    
    # æ£€æŸ¥æ˜¯å¦åœ¨HTTPæ¨¡å¼ä¸‹è¿è¡Œï¼ˆSmithery.aiå¹³å°ï¼‰
    if os.getenv("MCP_SERVER_MODE") == "http":
        # HTTPæ¨¡å¼ - ç”¨äºSmithery.aiå¹³å°
        logger.info("å¯åŠ¨HTTPæ¨¡å¼MCPæœåŠ¡...")
        fastmcp = FastMCP("dm-mcp")
        
        # æ³¨å†Œæ‰€æœ‰å·¥å…·
        @fastmcp.tool()
        async def test_connection() -> str:
            """æµ‹è¯•è¾¾æ¢¦æ•°æ®åº“è¿æ¥"""
            result = db.test_connection()
            return f"è¾¾æ¢¦æ•°æ®åº“è¿æ¥æµ‹è¯•: {'æˆåŠŸ' if result else 'å¤±è´¥'}"
        
        @fastmcp.tool()
        async def get_security_info() -> str:
            """è·å–å½“å‰å®‰å…¨é…ç½®ä¿¡æ¯"""
            security_info = db.get_security_info()
            info_text = "å½“å‰å®‰å…¨é…ç½®ä¿¡æ¯:\n\n"
            info_text += f"å®‰å…¨æ¨¡å¼: {security_info['security_mode']}\n"
            info_text += f"åªè¯»æ¨¡å¼: {'æ˜¯' if security_info['readonly_mode'] else 'å¦'}\n"
            info_text += f"å…è®¸å†™å…¥æ“ä½œ: {'æ˜¯' if security_info['write_allowed'] else 'å¦'}\n"
            info_text += f"å…è®¸å±é™©æ“ä½œ: {'æ˜¯' if security_info['dangerous_operations_allowed'] else 'å¦'}\n"
            info_text += f"å…è®¸è®¿é—®çš„æ¨¡å¼: {', '.join(security_info['allowed_schemas'])}\n"
            info_text += f"æœ€å¤§è¿”å›è¡Œæ•°: {security_info['max_result_rows']}\n"
            info_text += f"æŸ¥è¯¢æ—¥å¿—: {'å¯ç”¨' if security_info['query_log_enabled'] else 'ç¦ç”¨'}\n"
            return info_text
        
        # å¯åŠ¨HTTPæœåŠ¡å™¨
        import uvicorn
        uvicorn.run(fastmcp, host="0.0.0.0", port=8000)
    else:
        # æ ‡å‡†stdioæ¨¡å¼ - ç”¨äºæœ¬åœ°Cursor
        logger.info("å¯åŠ¨stdioæ¨¡å¼MCPæœåŠ¡...")
        async with stdio_server() as (read_stream, write_stream):
            await server.run(
                read_stream,
                write_stream,
                InitializationOptions(
                    server_name="dm-mcp",
                    server_version="1.0.0",
                    capabilities=server.get_capabilities(
                        notification_options=NotificationOptions(),
                        experimental_capabilities={}
                    )
                )
            )

if __name__ == "__main__":
    asyncio.run(main()) 